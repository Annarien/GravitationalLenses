{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.utils.data import get_pkg_data_filename\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathToPos = 'top1500processed/top1500processed_pos/'\n",
    "pathToNeg = 'top1500processed/top1500processed_neg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pathToPos = 'PositiveWithDESSky/'\n",
    "#pathToNeg = 'DES/DES_Processed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = {}\n",
    "for root, dirs, files in os.walk(pathToPos):\n",
    "    for folder in dirs:\n",
    "        key = folder\n",
    "        value = os.path.join(root, folder)\n",
    "        folders[key] = value\n",
    "        \n",
    "# subf = []\n",
    "# for folder in folders:\n",
    "#     subf.append(folder[len(pathToPos)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of Positive DataPoints\n",
    "nDT = len(folders)\n",
    "\n",
    "DataPos = np.zeros([nDT, 3, 100, 100])\n",
    "\n",
    "# key is name of folder number\n",
    "# value is the number of the folder to be added to the file name\n",
    "\n",
    "counter = 0\n",
    "for key, value in folders.items():\n",
    "    g_name = get_pkg_data_filename(value + '/' + str(key) + '_posSky_g_norm.fits')\n",
    "    r_name = get_pkg_data_filename(value + '/' + str(key) + '_posSky_r_norm.fits')\n",
    "    i_name = get_pkg_data_filename(value + '/' + str(key) + '_posSky_i_norm.fits')\n",
    "    \n",
    "#    g_name = get_pkg_data_filename(folders[var]+'/'+subf[var]+'g_WCSClipped.fits')\n",
    "#    r_name = get_pkg_data_filename(folders[var]+'/'+subf[var]+'r_WCSClipped.fits')\n",
    "#    i_name = get_pkg_data_filename(folders[var]+'/'+subf[var]+'i_WCSClipped.fits')\n",
    "    \n",
    "    \n",
    "    g = fits.open(g_name)[0].data[0:100,0:100]\n",
    "    r = fits.open(r_name)[0].data[0:100,0:100]\n",
    "    i = fits.open(i_name)[0].data[0:100,0:100]\n",
    "    \n",
    "    DataPos[counter] = [g, r, i] \n",
    "    counter += 1\n",
    "#    if counter > 1500:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading negative examples\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "\n",
    "foldersNeg = []\n",
    "for root, dirs, files in os.walk(pathToNeg):\n",
    "    for folder in dirs:\n",
    "        foldersNeg.append(os.path.join(root, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDT = len(foldersNeg)\n",
    "DataNeg = np.zeros([nDT,3,100,100])\n",
    "\n",
    "for var in range(len(folders)):\n",
    "#    g_name = get_pkg_data_filename(foldersNeg[var]+'/g_WCSClipped.fits')\n",
    "#    r_name = get_pkg_data_filename(foldersNeg[var]+'/r_WCSClipped.fits')\n",
    "#    i_name = get_pkg_data_filename(foldersNeg[var]+'/i_WCSClipped.fits')    \n",
    "\n",
    "    g_name = get_pkg_data_filename(foldersNeg[var]+'/g_norm.fits')\n",
    "    r_name = get_pkg_data_filename(foldersNeg[var]+'/r_norm.fits')\n",
    "    i_name = get_pkg_data_filename(foldersNeg[var]+'/i_norm.fits')    \n",
    "\n",
    "    g = fits.open(g_name)[0].data[0:100,0:100]\n",
    "    r = fits.open(r_name)[0].data[0:100,0:100]\n",
    "    i = fits.open(i_name)[0].data[0:100,0:100]    \n",
    "    \n",
    "    DataNeg[var] = [g, r, i]\n",
    "#    if var > 1500:\n",
    "#        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    m = x.mean()\n",
    "    v = x.std()\n",
    "    return (x-m)/v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "im2disp = DataNeg[20].transpose((1,2,0))\n",
    "pyplot.imshow(im2disp)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2disp = DataPos[20].transpose((1,2,0))\n",
    "pyplot.imshow(im2disp)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPos.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I have found an issue here:\n",
    "   DEF: The std is the quantity expressing by how much the members of a group differ from the mean value for the group.\n",
    "   \n",
    "   DataPos has a very low std, and this means that all the images are very similar. This is not exactly what we want as this doesnt have a huge difference when training, testing or validating. \n",
    "   \n",
    "   Since DataNeg std is so much bigger, there is quite a large variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataNeg.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllData = np.vstack(DataPos, DataNeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AllData.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian normalization of the data\n",
    "for i in range(DataPos.shape[0]):\n",
    "    for j in range(DataPos.shape[1]):\n",
    "        DataPos[i,j] = norm(DataPos[i,j])\n",
    "        #print(DataPos.std())\n",
    "\n",
    "for i in range(DataNeg.shape[0]):\n",
    "    for j in range(DataNeg.shape[1]):\n",
    "        DataNeg[i,j] = norm(DataNeg[i,j])\n",
    "        #print(DataNeg.std())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "im2disp = DataNeg[20].transpose((1,2,0))\n",
    "pyplot.imshow(im2disp)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im2disp = DataPos[20].transpose((1,2,0))\n",
    "pyplot.imshow(im2disp)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to create train and test \"datasets\",\n",
    "# let's say 80% images for training and 20% for test from every group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPos.shape[0]\n",
    "DataNeg.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rnd\n",
    "rnd.seed(2019) #fix seed for reproducibility of results \n",
    "\n",
    "listPos = list(np.arange(DataPos.shape[0]))\n",
    "listPosTest = list(rnd.choice(listPos,int(DataPos.shape[0]*0.2), replace=False))\n",
    "listPosRem = list(set(listPos)-set(listPosTest))\n",
    "listPosVal = list(rnd.choice(listPosRem,int(DataPos.shape[0]*0.2), replace=False))\n",
    "listPosTrain = list(set(listPosRem)-set(listPosVal))\n",
    "\n",
    "\n",
    "listNeg = list(np.arange(DataPos.shape[0],DataPos.shape[0]+DataNeg.shape[0]))\n",
    "listNegTest  = list(rnd.choice(listNeg,int(DataNeg.shape[0]*0.2), replace=False))\n",
    "listNegRem = list(set(listNeg)-set(listNegTest))\n",
    "listNegVal  = list(rnd.choice(listNegRem,int(DataNeg.shape[0]*0.2), replace=False))\n",
    "listNegTrain = list(set(listNegRem)-set(listNegVal))\n",
    "\n",
    "listTest  = listPosTest  + listNegTest\n",
    "rnd.shuffle(listTest)\n",
    "listVal  = listPosVal  + listNegVal\n",
    "rnd.shuffle(listVal)\n",
    "listTrain = listPosTrain + listNegTrain\n",
    "rnd.shuffle(listTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are ready to create X_train, Y_train and X_test and Y_test\n",
    "\n",
    "Ntest  = len(listTest)\n",
    "Nval   = len(listVal)\n",
    "Ntrain = len(listTrain)\n",
    "\n",
    "X_train = np.zeros([Ntrain,3,100,100])\n",
    "Y_train = np.zeros(Ntrain, dtype=int)\n",
    "\n",
    "X_test = np.zeros([Ntest,3,100,100])\n",
    "Y_test = np.zeros(Ntest, dtype=int)\n",
    "\n",
    "X_val = np.zeros([Nval,3,100,100])\n",
    "Y_val = np.zeros(Nval, dtype=int)\n",
    "\n",
    "\n",
    "for i in range(Ntest):\n",
    "    if listTest[i]<DataPos.shape[0]:\n",
    "        X_test[i] = DataPos[listTest[i]]\n",
    "        Y_test[i] = 1\n",
    "    else:\n",
    "        X_test[i] = DataNeg[listTest[i]-DataPos.shape[0]]\n",
    "        Y_test[i] = 0\n",
    "\n",
    "for i in range(Nval):\n",
    "    if listVal[i]<DataPos.shape[0]:\n",
    "        X_val[i] = DataPos[listVal[i]]\n",
    "        Y_val[i] = 1\n",
    "    else:\n",
    "        X_val[i] = DataNeg[listVal[i]-DataPos.shape[0]]\n",
    "        Y_val[i] = 0        \n",
    "        \n",
    "for i in range(Ntrain):\n",
    "    if listTrain[i]<DataPos.shape[0]:\n",
    "        X_train[i] = DataPos[listTrain[i]]\n",
    "        Y_train[i] = 1\n",
    "    else:\n",
    "        X_train[i] = DataNeg[listTrain[i]-DataPos.shape[0]]\n",
    "        Y_train[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test  = X_test.transpose(0,2,3,1)\n",
    "X_val   = X_val.transpose(0,2,3,1)\n",
    "X_train = X_train.transpose(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are almost ready to create CNN :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size = (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(4,4)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train, epochs=30, batch_size=200, validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can add more layers, DropOut and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model_baseline.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"accuracy on the test set ->\", acc * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPos.dump('DataPos.pkl')\n",
    "DataNeg.dump('DataNeg.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 84 good and 84 bad images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get path names for good and bad sources, where good sources are the \n",
    "# known sources and the bad sources are the unknown sources\n",
    "\n",
    "pathToKnown = 'KnownLenses/Known_Processed'\n",
    "pathToUnknown = 'DES/Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading known examples from Jacobs paper\n",
    "\n",
    "# r=root, d=directories, f = files\n",
    "\n",
    "foldersKnown = []\n",
    "for root, dirs, files in os.walk(pathToKnown):\n",
    "    for folder in dirs:\n",
    "        foldersKnown.append(os.path.join(root, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDT = len(foldersKnown)\n",
    "DataKnown = np.zeros([nDT,3,100,100])\n",
    "\n",
    "for var in range(len(foldersKnown)):\n",
    "#    g_name = get_pkg_data_filename(foldersKnown[var]+'/g_WCSClipped.fits')\n",
    "#    r_name = get_pkg_data_filename(foldersKnown[var]+'/r_WCSClipped.fits')\n",
    "#    i_name = get_pkg_data_filename(foldersKnown[var]+'/i_WCSClipped.fits')    \n",
    "\n",
    "    g_name = get_pkg_data_filename(foldersKnown[var]+'/g_norm.fits')\n",
    "    r_name = get_pkg_data_filename(foldersKnown[var]+'/r_norm.fits')\n",
    "    i_name = get_pkg_data_filename(foldersKnown[var]+'/i_norm.fits')    \n",
    "\n",
    "    g = fits.open(g_name)[0].data[0:100,0:100]\n",
    "    r = fits.open(r_name)[0].data[0:100,0:100]\n",
    "    i = fits.open(i_name)[0].data[0:100,0:100]    \n",
    "    \n",
    "    DataKnown[var] = [g, r, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading unknown examples from DES\n",
    "\n",
    "foldersUnknown = []\n",
    "for root, dirs, files in os.walk(pathToUnknown):\n",
    "    for folder in dirs:\n",
    "        foldersUnknown.append(os.path.join(root, folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDT = len(foldersUnknown)\n",
    "DataUnknown = np.zeros([nDT,3,100,100])\n",
    "\n",
    "for var in range(len(foldersUnknown)):\n",
    "#    g_name = get_pkg_data_filename(foldersUnknown[var]+'/g_WCSClipped.fits')\n",
    "#    r_name = get_pkg_data_filename(foldersUnknown[var]+'/r_WCSClipped.fits')\n",
    "#    i_name = get_pkg_data_filename(foldersUnknown[var]+'/i_WCSClipped.fits')    \n",
    "\n",
    "    g_name = get_pkg_data_filename(foldersUnknown[var]+'/g_norm.fits')\n",
    "    r_name = get_pkg_data_filename(foldersUnknown[var]+'/r_norm.fits')\n",
    "    i_name = get_pkg_data_filename(foldersUnknown[var]+'/i_norm.fits')    \n",
    "\n",
    "    g = fits.open(g_name)[0].data[0:100,0:100]\n",
    "    r = fits.open(r_name)[0].data[0:100,0:100]\n",
    "    i = fits.open(i_name)[0].data[0:100,0:100]    \n",
    "    \n",
    "    DataUnknown[var] = [g, r, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataKnown = DataKnown.transpose(0, 3, 2, 1)\n",
    "np.round(model.predict(DataKnown))\n",
    "print (\"Non zeros: \" +str(np.count_nonzero(model.predict(DataKnown))))\n",
    "print (\"length: \"+ str(len(DataKnown)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DataUnknown = DataUnknown.transpose(0, 3, 2, 1 )\n",
    "np.round(model.predict(DataUnknown))\n",
    "print (\"Non zeros: \" +str(np.count_nonzero(model.predict(DataUnknown))))\n",
    "print (\"length: \"+ str(len(DataUnknown)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}